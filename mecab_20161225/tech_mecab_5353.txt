[新聞]人工智慧時代須防範「人工智慧詐騙術」  - 看板 Tech_Job - 批踢踢實業坊作者zxcvxx (zxcvxx)看板Tech_Job標題[新聞]人工智慧時代須防範「人工智慧詐騙術」 時間Wed Oct  5 08:33:18 2016來源:http://bit.ly/2dIcUDiAlpha Go大勝韓國棋王，讓人類意識到人工智慧的能力以及重要性。然而研究發現，邏輯運算、推斷決策能力勝過人類的人工智慧，卻出乎意料地容易受騙。美國賓夕法尼亞州大學的研究團隊與Google、美國軍方共同針對人工智慧可能會面臨何種惡意攻擊？例如：沙沙聲的噪音有可能頻率內含有命令Siri、Google Now等智慧手機的虛擬助理進行某項功能的指令。在使用者毫不知情的情況下瀏覽含有病毒或木馬程式的網站、email，導致使用者的智慧手機中毒、個資外洩，甚至引發各種爭端。不僅如此，任何圖片被稍作修改後，人類肉眼看來兩張一模一樣的圖片，但在人工智慧演算法看來卻是截然不同的圖片（如圖一）。換言之，在人類眼中沒有異常的路面標誌或招牌，對於由人工智慧操控的無人駕駛車看來極有可能代表著不同意義，讓人工智慧錯誤判讀路面上的標誌而造成車禍。這類有別於傳統駭客入侵的「人工智慧詐騙術」，在人工智慧時代將成為人類社會極大的威脅。追根究底，人工智慧之所以如此容易受騙，是因為在機器學習過程中只讓人工智慧學習單方面的知識，使其可以回答或做出正確抉擇，但卻沒有教導人工智慧理解知識。因此，應該如同人類幼兒學習一樣，人工智慧在學習何謂正確知識時也要同時學習何謂錯誤，藉由同時正、反兩面的教導，讓人工智慧建立更難被黑箱攻擊的演算法，才能大幅降低人工智慧被騙的機率。身為前Google深度學習的主要研究人員之一，目前加入非營利人工智慧研究團隊的Open AI的Good Fellow博士表示，從實驗結果可以發現，如果只告訴人工智慧如何辨識什麼是正確的話，相對很容易被惡意重建另一套偽正確的演算法。然而，若將原始是的正確以及修改後的圖片同時給予人工智慧，訓練其辨識圖片的演算網絡時，則人工智慧錯認圖片的比率就會大幅減少，甚至人工智慧還能做得比原先的更好。除了Good Fellow博士外，近年來致力於發展爆裂物機器人、無人機、外骨骼機器人的美國軍方也針對人工智慧詐騙技術進行研究。畢竟美國軍方砸重金推動軍隊智慧化，如果輕易就被擊潰，反而導致國防門戶大開。除了美國軍方之外，將人工智慧技術視為企業次世代成長動力的IT企業也開始投入相關研究，希望能盡快彌補漏洞，好讓人工智慧技術發展不會因此受挫。--※ 發信站: 批踢踢實業坊(ptt.cc), 來自: 192.83.171.121※ 文章網址: https://www.ptt.cc/bbs/Tech_Job/M.1475627602.A.6A9.html→ pttworld: tay的復活之路遙無期。→ bowin: 是 Ian Goodfellow...→ wisdom: 人類的AI還沒發展出來就在思考避免AI受騙，所以IDF那種外→ wisdom: 星科技還會隨便被病毒入侵根本是鬼扯蛋推 drajan: Ian Goodfellow的GAN最近很火啊 原新聞也錯太大了..推文自動更新已關閉